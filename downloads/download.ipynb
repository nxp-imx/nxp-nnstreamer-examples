{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "# Copyright 2022 NXP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853551b",
   "metadata": {},
   "source": [
    "# Models download\n",
    "Purpose of this notebook is to download model sources and metadata used by the examples, and apply necessary conversion steps prior to execution. Resulting models will be located in the top level `downloads` directory.\n",
    "\n",
    "This notebook has dependency on availability of eIQ Toolkit environment being configured.\n",
    "Refer to [downloads\\README.md](./README.md) for instructions.\n",
    "\n",
    "## Preamble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import tarfile\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Repository directory\n",
    "top_dir = str(cwd.parent.absolute())\n",
    "# Models directory\n",
    "models_dir = os.path.join(top_dir, 'downloads', 'models')\n",
    "# Media directory\n",
    "media_dir = os.path.join(top_dir, 'downloads', 'media')\n",
    "# Work directory (temporary)\n",
    "tmp_dir = os.path.join(top_dir, 'tmp')\n",
    "# Small batch of pictures samples for post-training quantization\n",
    "samples_dir = os.path.join(top_dir, 'samples')\n",
    "\n",
    "# notebook dependency check:\n",
    "# eIQ environment verification\n",
    "if shutil.which('deepview-converter') is None:\n",
    "    raise FileNotFoundError('Need eIQ Toolkit environment setup - see downloads/README.md')\n",
    "\n",
    "# \n",
    "# General purpose helpers\n",
    "#\n",
    "\n",
    "# Download a list of files from urls\n",
    "# returns list of local file paths\n",
    "def fetch_urls(urls, dest_dir):\n",
    "    Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "    files = []\n",
    "    for url in urls:\n",
    "        path = urllib.parse.urlparse(url).path\n",
    "        file = os.path.basename(path)\n",
    "        dest_file = os.path.join(dest_dir, file)\n",
    "        print(f\"downloading {url} ({dest_file})\")\n",
    "        # wikimedia.org requires user agent\n",
    "        req = urllib.request.Request(\n",
    "                  url, data=None,\n",
    "                  headers= {'User-Agent' : 'download script/0.1'}\n",
    "              )\n",
    "        with urllib.request.urlopen(req) as resp:\n",
    "            with open(dest_file, 'wb') as dest:\n",
    "                content = resp.read()\n",
    "                dest.write(content)\n",
    "                files += [ dest_file ]\n",
    "    return files\n",
    "\n",
    "# download files and tarballs - extract archives when relevant\n",
    "def fetcher(items):\n",
    "    for item in items:\n",
    "        url = item['url']\n",
    "        dest = item['dest']\n",
    "        download = fetch_urls([url], dest)[0]\n",
    "        if download.endswith('.zip'):\n",
    "            with zipfile.ZipFile(download) as _zip:\n",
    "                print(f\"extracting zip {download}\")\n",
    "                _zip.extractall(path=dest)\n",
    "        if download.endswith('.tar.gz') or download.endswith('.tgz'):\n",
    "            with tarfile.open(download) as _tar:\n",
    "                print(f\"extracting tar {download}\")\n",
    "                _tar.extractall(path=dest)\n",
    "\n",
    "# Create list of clean (empty) directories\n",
    "def make_clean_dirs(dest_dirs):\n",
    "    for dest_dir in dest_dirs:\n",
    "        shutil.rmtree(dest_dir, ignore_errors=True)\n",
    "        Path(dest_dir).mkdir(parents=True)\n",
    "\n",
    "# Invoke deepview-converter with args\n",
    "def dvc(origin, dest, args=[]):\n",
    "    cmd = ['deepview-converter'] + args + [origin, dest]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "# Convert TFLite model (.tflite) to DeepViewRT (.rtm)\n",
    "def dvc_tflite_rtm(origin):\n",
    "    dest = re.sub('.tflite', '.rtm', origin)\n",
    "    dvc(origin, dest)\n",
    "    \n",
    "# Convert TFLite model (<name>.tflite) to Vela-processed TFLite (<name>_vela.tflite)\n",
    "def vela(origin, args=[]):\n",
    "    cmd = ['vela']\n",
    "    cmd += ['--output-dir', os.path.dirname(origin)]\n",
    "    cmd += args\n",
    "    cmd += [origin]\n",
    "    subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a few jpeg picture samples for post-training quantization (for demo)\n",
    "shutil.rmtree(samples_dir, ignore_errors=True)    \n",
    "samples = [\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Olea_europaea_cuspidata-africana_Cape_Town.JPG/605px-Olea_europaea_cuspidata-africana_Cape_Town.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Sport-orange-red-color-tennis-organ-491989-pxhere.jpg/640px-Sport-orange-red-color-tennis-organ-491989-pxhere.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Domesticated_goose_head%2C_Chaguaramal%2C_Venezuela.jpg/640px-Domesticated_goose_head%2C_Chaguaramal%2C_Venezuela.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/20080831-R0012506.JPG/640px-20080831-R0012506.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Pisa_Cathedral_%26_Bell_Tower_-_%22Leaning_Tower_of_Pisa%22_%289809628764%29.jpg/640px-Pisa_Cathedral_%26_Bell_Tower_-_%22Leaning_Tower_of_Pisa%22_%289809628764%29.jpg',\n",
    "    ]\n",
    "fetch_urls(samples, samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b3d51",
   "metadata": {},
   "source": [
    "# Detection\n",
    "## Artifacts download\n",
    "model: [ssdlite_mobilenet_v2_coco](ssdlite_mobilenet_v2_coco)<br>\n",
    "reference: [TensorFlow 1 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md#mobile-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ec7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'detection')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "model_float = 'ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz'\n",
    "url_float = urllib.parse.urljoin('http://download.tensorflow.org/models/object_detection/', model_float)\n",
    "packages = [\n",
    "    {'url'  : url_float,\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : 'https://github.com/nnsuite/testcases/raw/master/DeepLearningModels/tensorflow-lite/ssd_mobilenet_v2_coco/coco_labels_list.txt',\n",
    "     'dest' : dest_dir},\n",
    "    {'url'  : 'https://github.com/nnsuite/testcases/raw/master/DeepLearningModels/tensorflow-lite/ssd_mobilenet_v2_coco/box_priors.txt',\n",
    "     'dest' : dest_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)\n",
    "\n",
    "folder = re.sub('.tar.gz', '', model_float)\n",
    "pb_model = os.path.join(tmp_dir, folder, 'frozen_inference_graph.pb')\n",
    "\n",
    "model_darknet = 'yolov4-tiny.weights'\n",
    "url_darknet = urllib.parse.urljoin('https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights', model_darknet)\n",
    "packages = [\n",
    "    {'url'  : url_darknet,\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : 'https://raw.githubusercontent.com/amikelive/coco-labels/master/coco-labels-2014_2017.txt',\n",
    "     'dest' : dest_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd1581",
   "metadata": {},
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c384c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models (without box-decoding / NMS postprocessing)\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "tflite_float = os.path.join(dest_dir, 'ssdlite_mobilenet_v2_coco_no_postprocess.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,300,300,3']\n",
    "args += ['--input_names', 'Preprocessor/sub', '--output_names', 'concat,concat_1']\n",
    "dvc(pb_model, tflite_float, args)\n",
    "\n",
    "# convert TF -> TFLite (quantized)\n",
    "tflite_quant = os.path.join(dest_dir, 'ssdlite_mobilenet_v2_coco_quant_uint8_float32_no_postprocess.tflite')\n",
    "args  = ['--tflite_converter', 'toco', '--default_shape', '1,300,300,3']\n",
    "args += ['--quantize', '--quantize_format', 'int8']\n",
    "args += ['--input-type', 'uint8', '--output-type', 'float32']\n",
    "args += ['--input_names', 'Preprocessor/sub', '--output_names', 'concat,concat_1']\n",
    "dvc(pb_model, tflite_quant, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5047916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert Yolov4-tiny Darknet -> TFlite (quantized)\n",
    "# this script may take several minutes to complete\n",
    "!python3 {top_dir}/detection/yolov4-tiny_export_model.py \\\n",
    "--weights_path={tmp_dir} --output_path={dest_dir} --images_path={samples_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677985f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# DeepView RT models - converted from TFLite\n",
    "#\n",
    "\n",
    "# convert TFLite (float) -> DeepViewRT (float)\n",
    "dvc_tflite_rtm(tflite_float)\n",
    "\n",
    "# convert TFLite (quantized) -> DeepViewRT (quantized)\n",
    "dvc_tflite_rtm(tflite_quant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebc216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Vela-processed TFLite models targeting i.MX 93 Ethos-U NPU - converted from TFLite\n",
    "#\n",
    "\n",
    "# convert TFLite (quantized) -> Vela TFLite (quantized)\n",
    "vela(tflite_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11126519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Vela on quantized Yolov4-tiny\n",
    "\n",
    "# The model must have been exported from Darknet to TFLite before\n",
    "yolov4_tiny_416_quant = os.path.join(dest_dir, 'yolov4-tiny_416_quant.tflite')\n",
    "\n",
    "# convert TFLite (quantized) -> Vela TFLite (quantized)\n",
    "vela(yolov4_tiny_416_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95146a8d",
   "metadata": {},
   "source": [
    "#  Classification\n",
    "## Artifacts download\n",
    "model: [mobilenet_v1_1.0_224](http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz)<br>\n",
    "reference: [TensorFlow-Slim image classification model library](https://github.com/tensorflow/models/tree/master/research/slim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'classification')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "model_float = 'mobilenet_v1_1.0_224.tgz'\n",
    "model_quant = 'mobilenet_v1_1.0_224_quant.tgz'\n",
    "url_model = 'http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/'\n",
    "packages = [\n",
    "    {'url'  : urllib.parse.urljoin(url_model, model_float),\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : urllib.parse.urljoin(url_model, model_quant),\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : 'https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_1.0_224_quant_and_labels.zip',\n",
    "     'dest' : tmp_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)\n",
    "\n",
    "pb_model_float = os.path.join(tmp_dir, 'mobilenet_v1_1.0_224_frozen.pb')\n",
    "pb_model_quant = os.path.join(tmp_dir, 'mobilenet_v1_1.0_224_quant_frozen.pb')\n",
    "\n",
    "labels_file = os.path.join(tmp_dir, 'labels_mobilenet_quant_v1_224.txt')\n",
    "shutil.copy2(labels_file, dest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80733e7b",
   "metadata": {},
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3307ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "tflite_float = os.path.join(dest_dir, 'mobilenet_v1_1.0_224.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,224,224,3']\n",
    "args += ['--input_names', 'input', '--output_names', 'MobilenetV1/Predictions/Reshape_1']\n",
    "dvc(pb_model_float, tflite_float, args)\n",
    "\n",
    "# convert TF -> TFLite (quantized)\n",
    "tflite_quant = os.path.join(dest_dir, 'mobilenet_v1_1.0_224_quant_uint8_float32.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,224,224,3']\n",
    "args += ['--quantize', '--quantize_format', 'int8']\n",
    "args += ['--input-type', 'uint8', '--output-type', 'float32']\n",
    "args += ['--samples', samples_dir]\n",
    "args += ['--input_names', 'input', '--output_names', 'MobilenetV1/Predictions/Reshape_1']\n",
    "dvc(pb_model_float, tflite_quant, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664176d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# DeepView RT models - converted from TFLite\n",
    "#\n",
    "\n",
    "# convert TFLite (float) -> DeepViewRT (float)\n",
    "dvc_tflite_rtm(tflite_float)\n",
    "\n",
    "# convert TFLite (quantized) -> DeepViewRT (quantized)\n",
    "dvc_tflite_rtm(tflite_quant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ed60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Vela-processed TFLite models targeting i.MX 93 Ethos-U NPU - converted from TFLite\n",
    "#\n",
    "\n",
    "# convert TFLite (quantized) -> Vela TFLite (quantized)\n",
    "vela(tflite_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a17ac",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "## Artifacts download\n",
    "model: [deeplabv3_mnv2_dm05](http://download.tensorflow.org/models/deeplabv3_mnv2_dm05_pascal_trainaug_2018_10_01.tar.gz)<br>\n",
    "references: \n",
    "1. [TensorFlow DeepLab Model Zoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md)<br>\n",
    "2. [Quantize DeepLab model for faster on-device inference](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/quantize.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'segmentation')\n",
    "images_dir = os.path.join(media_dir, 'pascal_voc_2012_images')\n",
    "make_clean_dirs([tmp_dir, dest_dir, images_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "model_float = 'deeplabv3_mnv2_dm05_pascal_trainaug_2018_10_01.tar.gz'\n",
    "model_quant = 'deeplabv3_mnv2_dm05_pascal_train_aug_8bit_2019_04_26.tar.gz'\n",
    "url_model = 'http://download.tensorflow.org/models/'\n",
    "packages = [\n",
    "    {'url'  : urllib.parse.urljoin(url_model, model_float),\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : urllib.parse.urljoin(url_model, model_quant),\n",
    "     'dest' : tmp_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)\n",
    "\n",
    "pb_model_float = os.path.join(tmp_dir, 'deeplabv3_mnv2_dm05_pascal_trainaug','frozen_inference_graph.pb')\n",
    "pb_model_quant = os.path.join(tmp_dir, 'deeplabv3_mnv2_dm05_pascal_trainaug_8bit','frozen_inference_graph.pb')\n",
    "\n",
    "# fetch and rename a few images relevant to pascal voc 2012 data set\n",
    "images = [\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Plectranthus_verticillatus_in_a_ceramic_pot.jpg/640px-Plectranthus_verticillatus_in_a_ceramic_pot.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Maceta.jpg/566px-Maceta.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Stray_Cat%2C_Nafplio.jpg/800px-Stray_Cat%2C_Nafplio.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Feral_cat_7.jpg/800px-Feral_cat_7.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/0/0a/Senior-lady-dog-walker.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Texel_ewe_and_three_lambs.jpg/800px-Texel_ewe_and_three_lambs.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Cow_farm_in_Bemmel%2C_Lingewaard.jpg/800px-Cow_farm_in_Bemmel%2C_Lingewaard.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Urban_cycling_III.jpg/800px-Urban_cycling_III.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/LomondRoadsTTRider.jpg/467px-LomondRoadsTTRider.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/Interceptor_of_Bangalore_Traffic_Police.jpg/640px-Interceptor_of_Bangalore_Traffic_Police.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Ranger_clearing_traffic_at_a_bison_jam_in_Lamar_Valley_%2848fe8fe3-c1e3-4828-acec-496eaef43503%29.jpg/800px-Ranger_clearing_traffic_at_a_bison_jam_in_Lamar_Valley_%2848fe8fe3-c1e3-4828-acec-496eaef43503%29.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Finnair.a320-200.oh-lxf.arp.jpg/800px-Finnair.a320-200.oh-lxf.arp.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/G-BGMP_Reims_F172_%40Cotswold_Airport%2C_July_2005.jpg/800px-G-BGMP_Reims_F172_%40Cotswold_Airport%2C_July_2005.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/JNR_14_series_sleeper_Blue_Train_Hayabusa.jpg/640px-JNR_14_series_sleeper_Blue_Train_Hayabusa.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/7122_series_train_%2812%29.JPG/640px-7122_series_train_%2812%29.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Blue_fishing_boat_harbour_Eretria_Euboea_Greece.jpg/611px-Blue_fishing_boat_harbour_Eretria_Euboea_Greece.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/KYOEI_boat_in_Kisarazu_port_3.jpg/640px-KYOEI_boat_in_Kisarazu_port_3.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Jarritos_glass_bottle_%28Mexico%29.jpg/450px-Jarritos_glass_bottle_%28Mexico%29.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Andechser_3_beers.JPG/798px-Andechser_3_beers.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Ski_Citrus_Soda_%2825395355114%29.jpg/640px-Ski_Citrus_Soda_%2825395355114%29.jpg',\n",
    "]\n",
    "files = fetch_urls(images, tmp_dir)\n",
    "count = 0\n",
    "# rename files name as <image%04d.jpg>\n",
    "for src in files:\n",
    "    dest = os.path.join(images_dir, f'image{count:04}.jpg')\n",
    "    count += 1\n",
    "    shutil.copy2(src, dest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fc2f0",
   "metadata": {},
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f220698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "tflite_float = os.path.join(dest_dir, 'deeplabv3_mnv2_dm05_pascal.tflite')\n",
    "args = ['--tflite_converter', 'toco', '--default_shape', '1,513,513,3']\n",
    "args += ['--input_names', 'MobilenetV2/MobilenetV2/input', '--output_names', 'ResizeBilinear_2']\n",
    "dvc(pb_model_float, tflite_float, args)\n",
    "\n",
    "# convert TF -> TFLite (quantized)\n",
    "tflite_quant = os.path.join(dest_dir, 'deeplabv3_mnv2_dm05_pascal_quant_uint8_float32.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,513,513,3']\n",
    "args += ['--quantize', '--quantize_format', 'int8']\n",
    "args += ['--input-type', 'uint8', '--output-type', 'float32']\n",
    "args += ['--samples', samples_dir]\n",
    "args += ['--input_names', 'MobilenetV2/MobilenetV2/input', '--output_names', 'ResizeBilinear_2']\n",
    "dvc(pb_model_float, tflite_quant, args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c9353",
   "metadata": {},
   "source": [
    "# Pose\n",
    "## Artifacts download\n",
    "model: [movenet/singlepose/lightning TF2 SavedModel](https://storage.googleapis.com/tfhub-modules/google/movenet/singlepose/lightning/4.tar.gz)<br>\n",
    "references: \n",
    "1. [TensorFlow Hub Image Pose Detection](https://tfhub.dev/s?module-type=image-pose-detection)<br>\n",
    "2. [TensorFlow Pose](https://www.tensorflow.org/lite/examples/pose_estimation/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf94be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'pose')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "movies_dir = os.path.join(media_dir, 'movies')\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "url_model = 'https://storage.googleapis.com/tfhub-modules/google/movenet/singlepose/lightning/4.tar.gz'\n",
    "packages = [{'url' :url_model, 'dest': tmp_dir},]\n",
    "fetcher(packages)\n",
    "\n",
    "pb_model_float = os.path.join(tmp_dir, 'saved_model.pb')\n",
    "\n",
    "# Download movie\n",
    "url_movie = 'https://upload.wikimedia.org/wikipedia/commons/transcoded/1/17/Conditioning_Drill_1-_Power_Jump.webm/Conditioning_Drill_1-_Power_Jump.webm.480p.vp9.webm'\n",
    "packages = [{'url': url_movie, 'dest': movies_dir},]\n",
    "fetcher(packages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c22cb",
   "metadata": {},
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbacb9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "# XXX: Toco converter crashes\n",
    "tflite_float = os.path.join(dest_dir, 'movenet_single_pose_lightning.tflite')\n",
    "args=[]\n",
    "dvc(pb_model_float, tflite_float, args)\n",
    "\n",
    "# TODO: quantized model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae5294",
   "metadata": {},
   "source": [
    "# Postamble / cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove temporary directories\n",
    "shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "shutil.rmtree(samples_dir, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
