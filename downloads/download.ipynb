{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bda40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "# Copyright 2022-2023, 2025 NXP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853551b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Models download\n",
    "Purpose of this notebook is to download model sources and metadata used by the examples, and apply necessary conversion steps prior to execution. Resulting models will be located in the top level `downloads` directory.\n",
    "\n",
    "This notebook has dependency on availability of eIQ Toolkit environment being configured.\n",
    "Refer to [downloads\\README.md](./README.md) for instructions.\n",
    "\n",
    "## Preamble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3f0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import tarfile\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Repository directory\n",
    "top_dir = str(cwd.parent.absolute())\n",
    "# Models directory\n",
    "models_dir = os.path.join(top_dir, 'downloads', 'models')\n",
    "# Media directory\n",
    "media_dir = os.path.join(top_dir, 'downloads', 'media')\n",
    "# Work directory (temporary)\n",
    "tmp_dir = os.path.join(top_dir, 'tmp')\n",
    "# Small batch of pictures samples for post-training quantization\n",
    "samples_dir = os.path.join(top_dir, 'samples')\n",
    "# Neutron converter binary\n",
    "neutron_converter_path = os.path.join(os.getenv('EIQ_BASE'), 'neutron-tuning/neutron-converter')\n",
    "\n",
    "# notebook dependency check:\n",
    "# eIQ environment verification\n",
    "if shutil.which('eiq-converter') is None:\n",
    "    raise FileNotFoundError('Need eIQ Toolkit environment setup - see downloads/README.md')\n",
    "\n",
    "# \n",
    "# General purpose helpers\n",
    "#\n",
    "\n",
    "# Download a list of files from urls\n",
    "# returns list of local file paths\n",
    "def fetch_urls(urls, dest_dir):\n",
    "    Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "    files = []\n",
    "    for url in urls:\n",
    "        path = urllib.parse.urlparse(url).path\n",
    "        file = os.path.basename(path)\n",
    "        dest_file = os.path.join(dest_dir, file)\n",
    "        print(f\"downloading {url} ({dest_file})\")\n",
    "        # wikimedia.org requires user agent\n",
    "        req = urllib.request.Request(\n",
    "                  url, data=None,\n",
    "                  headers= {'User-Agent' : 'download script/0.1'}\n",
    "              )\n",
    "        with urllib.request.urlopen(req) as resp:\n",
    "            with open(dest_file, 'wb') as dest:\n",
    "                content = resp.read()\n",
    "                dest.write(content)\n",
    "                files += [ dest_file ]\n",
    "    return files\n",
    "\n",
    "# download files and tarballs - extract archives when relevant\n",
    "def fetcher(items):\n",
    "    for item in items:\n",
    "        url = item['url']\n",
    "        dest = item['dest']\n",
    "        download = fetch_urls([url], dest)[0]\n",
    "        if download.endswith('.zip'):\n",
    "            with zipfile.ZipFile(download) as _zip:\n",
    "                print(f\"extracting zip {download}\")\n",
    "                _zip.extractall(path=dest)\n",
    "        if download.endswith('.tar.gz') or download.endswith('.tgz'):\n",
    "            with tarfile.open(download) as _tar:\n",
    "                print(f\"extracting tar {download}\")\n",
    "                _tar.extractall(path=dest)\n",
    "\n",
    "# Create list of clean (empty) directories\n",
    "def make_clean_dirs(dest_dirs):\n",
    "    for dest_dir in dest_dirs:\n",
    "        shutil.rmtree(dest_dir, ignore_errors=True)\n",
    "        Path(dest_dir).mkdir(parents=True)\n",
    "\n",
    "# Invoke eiq-converter with args\n",
    "def eiq_converter(origin, dest, args=[], plugin='tflite'):\n",
    "    plugin = ['--plugin', 'eiq-converter-' + plugin]\n",
    "    cmd = ['eiq-converter'] + plugin + args + [origin, dest]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "# Invoke neutron-converter with args\n",
    "def neutron_converter(origin, dest, args=['--target', 'imx95', '--use-python-prototype']):\n",
    "    cmd = [neutron_converter_path, '--input'] + [origin] + args + ['--output'] + [dest]\n",
    "    subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26e773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download a few jpeg picture samples for post-training quantization (for demo)\n",
    "shutil.rmtree(samples_dir, ignore_errors=True)    \n",
    "samples = [\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Olea_europaea_cuspidata-africana_Cape_Town.JPG/605px-Olea_europaea_cuspidata-africana_Cape_Town.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Sport-orange-red-color-tennis-organ-491989-pxhere.jpg/640px-Sport-orange-red-color-tennis-organ-491989-pxhere.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Domesticated_goose_head%2C_Chaguaramal%2C_Venezuela.jpg/640px-Domesticated_goose_head%2C_Chaguaramal%2C_Venezuela.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/20080831-R0012506.JPG/640px-20080831-R0012506.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Pisa_Cathedral_%26_Bell_Tower_-_%22Leaning_Tower_of_Pisa%22_%289809628764%29.jpg/640px-Pisa_Cathedral_%26_Bell_Tower_-_%22Leaning_Tower_of_Pisa%22_%289809628764%29.jpg',\n",
    "    ]\n",
    "fetch_urls(samples, samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b3d51",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Object Detection\n",
    "## Artifacts download\n",
    "\n",
    "| models | references | \n",
    "| :- | :- |\n",
    "| [ssdlite_mobilenet_v2_coco](http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz) | [TensorFlow 1 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md#mobile-models) |\n",
    "| [YoloV4-tiny](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights) | [Yolo Original Implementation in Darknet](https://github.com/AlexeyAB/darknet#pre-trained-models) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ec7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'object-detection')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "model_float = 'ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz'\n",
    "url_float = urllib.parse.urljoin('http://download.tensorflow.org/models/object_detection/', model_float)\n",
    "packages = [\n",
    "    {'url'  : url_float,\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : 'https://github.com/nnsuite/testcases/raw/master/DeepLearningModels/tensorflow-lite/ssd_mobilenet_v2_coco/coco_labels_list.txt',\n",
    "     'dest' : dest_dir},\n",
    "    {'url'  : 'https://github.com/nnsuite/testcases/raw/master/DeepLearningModels/tensorflow-lite/ssd_mobilenet_v2_coco/box_priors.txt',\n",
    "     'dest' : dest_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)\n",
    "\n",
    "folder = re.sub('.tar.gz', '', model_float)\n",
    "pb_model = os.path.join(tmp_dir, folder, 'frozen_inference_graph.pb')\n",
    "\n",
    "model_darknet = 'yolov4-tiny.weights'\n",
    "url_darknet = urllib.parse.urljoin('https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights', model_darknet)\n",
    "packages = [\n",
    "    {'url'  : url_darknet,\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : 'https://raw.githubusercontent.com/amikelive/coco-labels/master/coco-labels-2014_2017.txt',\n",
    "     'dest' : dest_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd1581",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c384c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models (without box-decoding / NMS postprocessing)\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "tflite_float = os.path.join(dest_dir, 'ssdlite_mobilenet_v2_coco_no_postprocess.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,300,300,3']\n",
    "args += ['--input_names', 'Preprocessor/sub', '--output_names', 'concat,concat_1']\n",
    "eiq_converter(pb_model, tflite_float, args)\n",
    "\n",
    "# convert TF -> TFLite (quantized)\n",
    "tflite_quant = os.path.join(dest_dir, 'ssdlite_mobilenet_v2_coco_quant_uint8_float32_no_postprocess.tflite')\n",
    "args  = ['--tflite_converter', 'toco', '--default_shape', '1,300,300,3']\n",
    "args += ['--quantize', '--quantize_format', 'int8']\n",
    "args += ['--input-type', 'uint8', '--output-type', 'float32']\n",
    "args += ['--input_names', 'Preprocessor/sub', '--output_names', 'concat,concat_1']\n",
    "eiq_converter(pb_model, tflite_quant, args)\n",
    "\n",
    "# convert TFLite (quantized) -> TFLite (neutron)\n",
    "tflite_neutron = os.path.join(dest_dir, 'ssdlite_mobilenet_v2_coco_quant_uint8_float32_no_postprocess_neutron.tflite')\n",
    "neutron_converter(tflite_quant, tflite_neutron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5047916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert Yolov4-tiny Darknet -> TFlite (quantized)\n",
    "# this script may take several minutes to complete\n",
    "!python3 {top_dir}/tasks/object-detection/yolov4-tiny_export_model.py \\\n",
    "--weights_path={tmp_dir} --output_path={dest_dir} --images_path={samples_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95146a8d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#  Classification\n",
    "## Artifacts download\n",
    "| model | reference | \n",
    "| :- | :- |\n",
    "| [mobilenet_v1_1.0_224](http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz) | [TensorFlow-Slim image classification model library](https://github.com/tensorflow/models/tree/master/research/slim) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e6e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'classification')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "model_float = 'mobilenet_v1_1.0_224.tgz'\n",
    "url_model = 'http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/'\n",
    "packages = [\n",
    "    {'url'  : urllib.parse.urljoin(url_model, model_float),\n",
    "     'dest' : tmp_dir},\n",
    "    {'url'  : 'https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_1.0_224_quant_and_labels.zip',\n",
    "     'dest' : tmp_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)\n",
    "\n",
    "pb_model_float = os.path.join(tmp_dir, 'mobilenet_v1_1.0_224_frozen.pb')\n",
    "\n",
    "labels_file = os.path.join(tmp_dir, 'labels_mobilenet_quant_v1_224.txt')\n",
    "shutil.copy2(labels_file, dest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80733e7b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3307ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "tflite_float = os.path.join(dest_dir, 'mobilenet_v1_1.0_224.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,224,224,3']\n",
    "args += ['--input_names', 'input', '--output_names', 'MobilenetV1/Predictions/Reshape_1']\n",
    "eiq_converter(pb_model_float, tflite_float, args)\n",
    "\n",
    "# convert TF -> TFLite (quantized)\n",
    "tflite_quant = os.path.join(dest_dir, 'mobilenet_v1_1.0_224_quant_uint8_float32.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,224,224,3']\n",
    "args += ['--quantize', '--quantize_format', 'int8']\n",
    "args += ['--input-type', 'uint8', '--output-type', 'float32']\n",
    "args += ['--samples', samples_dir]\n",
    "args += ['--input_names', 'input', '--output_names', 'MobilenetV1/Predictions/Reshape_1']\n",
    "eiq_converter(pb_model_float, tflite_quant, args)\n",
    "\n",
    "# convert TFLite (quantized) -> TFLite (neutron)\n",
    "tflite_neutron = os.path.join(dest_dir, 'mobilenet_v1_1.0_224_quant_uint8_float32_neutron.tflite')\n",
    "neutron_converter(tflite_quant, tflite_neutron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a17ac",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Semantic Segmentation\n",
    "## Artifacts download\n",
    "| model | references | \n",
    "| :- | :- |\n",
    "| [deeplabv3_mnv2_dm05](http://download.tensorflow.org/models/deeplabv3_mnv2_dm05_pascal_trainaug_2018_10_01.tar.gz) | [TensorFlow DeepLab Model Zoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md) <br> [Quantize DeepLab model for faster on-device inference](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/quantize.md) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85aea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'semantic-segmentation')\n",
    "images_dir = os.path.join(media_dir, 'pascal_voc_2012_images')\n",
    "make_clean_dirs([tmp_dir, dest_dir, images_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "model_float = 'deeplabv3_mnv2_dm05_pascal_trainaug_2018_10_01.tar.gz'\n",
    "url_model = 'http://download.tensorflow.org/models/'\n",
    "packages = [\n",
    "    {'url'  : urllib.parse.urljoin(url_model, model_float),\n",
    "     'dest' : tmp_dir},\n",
    "]\n",
    "\n",
    "fetcher(packages)\n",
    "\n",
    "pb_model_float = os.path.join(tmp_dir, 'deeplabv3_mnv2_dm05_pascal_trainaug','frozen_inference_graph.pb')\n",
    "\n",
    "# fetch and rename a few images relevant to pascal voc 2012 data set\n",
    "images = [\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Plectranthus_verticillatus_in_a_ceramic_pot.jpg/640px-Plectranthus_verticillatus_in_a_ceramic_pot.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Maceta.jpg/566px-Maceta.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Stray_Cat%2C_Nafplio.jpg/800px-Stray_Cat%2C_Nafplio.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Feral_cat_7.jpg/800px-Feral_cat_7.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/0/0a/Senior-lady-dog-walker.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Texel_ewe_and_three_lambs.jpg/800px-Texel_ewe_and_three_lambs.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Cow_farm_in_Bemmel%2C_Lingewaard.jpg/800px-Cow_farm_in_Bemmel%2C_Lingewaard.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Urban_cycling_III.jpg/800px-Urban_cycling_III.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/LomondRoadsTTRider.jpg/467px-LomondRoadsTTRider.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/Interceptor_of_Bangalore_Traffic_Police.jpg/640px-Interceptor_of_Bangalore_Traffic_Police.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Ranger_clearing_traffic_at_a_bison_jam_in_Lamar_Valley_%2848fe8fe3-c1e3-4828-acec-496eaef43503%29.jpg/800px-Ranger_clearing_traffic_at_a_bison_jam_in_Lamar_Valley_%2848fe8fe3-c1e3-4828-acec-496eaef43503%29.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Finnair.a320-200.oh-lxf.arp.jpg/800px-Finnair.a320-200.oh-lxf.arp.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/G-BGMP_Reims_F172_%40Cotswold_Airport%2C_July_2005.jpg/800px-G-BGMP_Reims_F172_%40Cotswold_Airport%2C_July_2005.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/JNR_14_series_sleeper_Blue_Train_Hayabusa.jpg/640px-JNR_14_series_sleeper_Blue_Train_Hayabusa.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/7122_series_train_%2812%29.JPG/640px-7122_series_train_%2812%29.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Blue_fishing_boat_harbour_Eretria_Euboea_Greece.jpg/611px-Blue_fishing_boat_harbour_Eretria_Euboea_Greece.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/KYOEI_boat_in_Kisarazu_port_3.jpg/640px-KYOEI_boat_in_Kisarazu_port_3.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Jarritos_glass_bottle_%28Mexico%29.jpg/450px-Jarritos_glass_bottle_%28Mexico%29.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Andechser_3_beers.JPG/798px-Andechser_3_beers.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Ski_Citrus_Soda_%2825395355114%29.jpg/640px-Ski_Citrus_Soda_%2825395355114%29.jpg',\n",
    "]\n",
    "files = fetch_urls(images, tmp_dir)\n",
    "count = 0\n",
    "# rename files name as <image%04d.jpg>\n",
    "for src in files:\n",
    "    dest = os.path.join(images_dir, f'image{count:04}.jpg')\n",
    "    count += 1\n",
    "    shutil.copy2(src, dest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fc2f0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f220698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "tflite_float = os.path.join(dest_dir, 'deeplabv3_mnv2_dm05_pascal.tflite')\n",
    "args = ['--tflite_converter', 'toco', '--default_shape', '1,513,513,3']\n",
    "args += ['--input_names', 'MobilenetV2/MobilenetV2/input', '--output_names', 'ResizeBilinear_2']\n",
    "eiq_converter(pb_model_float, tflite_float, args)\n",
    "\n",
    "# convert TF -> TFLite (quantized)\n",
    "tflite_quant = os.path.join(dest_dir, 'deeplabv3_mnv2_dm05_pascal_quant_uint8_float32.tflite')\n",
    "args =  ['--tflite_converter', 'toco', '--default_shape', '1,513,513,3']\n",
    "args += ['--quantize', '--quantize_format', 'int8']\n",
    "args += ['--input-type', 'uint8', '--output-type', 'float32']\n",
    "args += ['--samples', samples_dir]\n",
    "args += ['--input_names', 'MobilenetV2/MobilenetV2/input', '--output_names', 'ResizeBilinear_2']\n",
    "eiq_converter(pb_model_float, tflite_quant, args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c9353",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Pose Estimation\n",
    "## Artifacts download\n",
    "| model | references | \n",
    "| :- | :- |\n",
    "| [movenet/singlepose/lightning TF2 SavedModel](https://storage.googleapis.com/tfhub-modules/google/movenet/singlepose/lightning/4.tar.gz) | [TensorFlow Hub Image Pose Detection](https://tfhub.dev/s?module-type=image-pose-detection) <br> [TensorFlow Pose](https://www.tensorflow.org/lite/examples/pose_estimation/overview) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf94be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'pose-estimation')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "movies_dir = os.path.join(media_dir, 'movies')\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "url_model = 'https://storage.googleapis.com/tfhub-modules/google/movenet/singlepose/lightning/4.tar.gz'\n",
    "packages = [{'url' :url_model, 'dest': tmp_dir},]\n",
    "fetcher(packages)\n",
    "\n",
    "pb_model_float = os.path.join(tmp_dir, 'saved_model.pb')\n",
    "\n",
    "# Download movie\n",
    "url_movie = 'https://upload.wikimedia.org/wikipedia/commons/transcoded/1/17/Conditioning_Drill_1-_Power_Jump.webm/Conditioning_Drill_1-_Power_Jump.webm.480p.vp9.webm'\n",
    "packages = [{'url': url_movie, 'dest': movies_dir},]\n",
    "fetcher(packages)\n",
    "\n",
    "# quantized model to be downloaded from network\n",
    "\n",
    "url_models = 'https://github.com/NXP/nxp-vision-model-zoo/releases/download/v1.1/nxp_eiq_vision_model_zoo_v1.1.tgz'\n",
    "packages = [{'url' :url_models, 'dest': tmp_dir},]\n",
    "fetcher(packages)\n",
    "\n",
    "models_tmp_dir = os.path.join(tmp_dir, 'tasks')\n",
    "\n",
    "!cp {models_tmp_dir}/pose-estimation/movenet/movenet.tflite \\\n",
    "{dest_dir}/movenet_quant.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c22cb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Models conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbacb9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TFLite models\n",
    "#\n",
    "\n",
    "# convert TF -> TFLite (float)\n",
    "# XXX: Toco converter crashes\n",
    "tflite_float = os.path.join(dest_dir, 'movenet_single_pose_lightning.tflite')\n",
    "args=[]\n",
    "eiq_converter(pb_model_float, tflite_float, args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc0153",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Face Processing\n",
    "## Artifacts download\n",
    "| models | references | \n",
    "| :- | :- |\n",
    "| [FaceNet512](https://github.com/serengil/deepface_models/releases/download/v1.0/facenet512_weights.h5) | [Deepface repository](https://github.com/serengil/deepface/tree/master/deepface/basemodels) |\n",
    "| [Ultraface-slim](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/blob/master/models/pretrained/version-slim-320.pth) | [Ultra-Light-Fast-Generic-Face-Detector repository](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) |\n",
    "|[Deepface-emotion](https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5) | [Deepface repository](https://github.com/serengil/deepface/blob/master/deepface/extendedmodels/Emotion.py) |\n",
    "\n",
    "These models are downloaded from [NXP vision model zoo](https://github.com/NXP/nxp-vision-model-zoo) where they have been quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406558e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'face-processing')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "\n",
    "url_models = 'https://github.com/NXP/nxp-vision-model-zoo/releases/download/v1.0/nxp_eiq_vision_model_zoo_v1.0.tgz'\n",
    "packages = [{'url' :url_models, 'dest': tmp_dir},]\n",
    "fetcher(packages)\n",
    "\n",
    "models_tmp_dir = os.path.join(tmp_dir, 'tasks')\n",
    "\n",
    "!cp {models_tmp_dir}/object-detection/ultraface-slim/ultraface_slim_uint8_float32.tflite \\\n",
    "{models_tmp_dir}/face-recognition/facenet512/facenet512_uint8.tflite \\\n",
    "{models_tmp_dir}/classification/deepface-emotion/emotion_uint8_float32.tflite \\\n",
    "{dest_dir}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f88c3a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db1a21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert TFLite (quantized) -> TFLite (neutron)\n",
    "tflite_quant = os.path.join(models_tmp_dir, 'object-detection/ultraface-slim/ultraface_slim_uint8_float32.tflite')\n",
    "tflite_neutron = os.path.join(dest_dir, 'ultraface_slim_uint8_float32_neutron.tflite')\n",
    "neutron_converter(tflite_quant, tflite_neutron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4560f3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Monocular Depth Estimation\n",
    "## Artifacts download\n",
    "| models | references | \n",
    "| :- | :- |\n",
    "| Midasv2 | [Midas repository](https://www.kaggle.com/models/intel/midas/tfLite/v2-1-small-lite/1) |\n",
    "\n",
    "The model is downloaded from kaggle, its performances and quantization process are available on [NXP vision model zoo](https://github.com/NXP/nxp-vision-model-zoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14006c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start from clean state\n",
    "dest_dir = os.path.join(models_dir, 'monocular-depth-estimation')\n",
    "make_clean_dirs([tmp_dir, dest_dir])\n",
    "\n",
    "# models and metadata to be downloaded from network\n",
    "\n",
    "model_float = os.path.join(dest_dir, '')\n",
    "url_models = 'https://www.kaggle.com/api/v1/models/intel/midas/tfLite/v2-1-small-lite/1/download/1.tflite'\n",
    "packages = [{'url' :url_models, 'dest': dest_dir},]\n",
    "fetcher(packages)\n",
    "\n",
    "model_float = os.path.join(dest_dir, '1.tflite')\n",
    "renamed_model_float = os.path.join(dest_dir, 'midas_2_1_small_float32.tflite')\n",
    "os.rename(model_float, renamed_model_float)\n",
    "\n",
    "!cp {renamed_model_float} {tmp_dir}/midas_2_1_small_float32.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621d0356",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5fbd72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(tmp_dir)\n",
    "\n",
    "# convert TFLite -> TF for quantization process\n",
    "req_dir = os.path.join(top_dir, 'tasks/monocular-depth-estimation/requirements.txt')\n",
    "script_dir = os.path.join(top_dir, 'tasks/monocular-depth-estimation/export_midas-v2_to_TensorFlow.sh')\n",
    "os.system('chmod a+x ' + script_dir)\n",
    "os.system('bash ' + script_dir + ' ' + req_dir)\n",
    "\n",
    "# convert TF -> TFLite (quantized)\n",
    "pb_model = os.path.join(tmp_dir, 'model_float32.pb')\n",
    "tflite_quant = os.path.join(dest_dir, 'midas_2_1_small_int8_quant.tflite')\n",
    "args  = ['--tflite_converter', 'toco', '--default_shape', '1,256,256,3']\n",
    "args += ['--quantize', '--quantize_format', 'int8']\n",
    "args += ['--input-type', 'uint8', '--output-type', 'float32']\n",
    "args += ['--input_names', 'Const', '--output_names', 'midas_net_custom/sequential/re_lu_9/Relu']\n",
    "eiq_converter(pb_model, tflite_quant, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae5294",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Postamble / cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299cadc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove temporary directories\n",
    "shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "shutil.rmtree(samples_dir, ignore_errors=True)\n",
    "os.remove(os.path.join(top_dir, 'downloads/model.elf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
